{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2ae588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:77: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df2['label'][df2['label'] == 1] = 2\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['label'][df2['label'] == 1] = 2\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:78: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df2['label'][df2['label'] == 0] = 1\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['label'][df2['label'] == 0] = 1\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:79: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df2['label'][df2['label'] == 2] = 0\n",
      "c:\\Users\\rrpra\\Documents\\Github\\git_testing\\Phishing_URL_classifier_using_nlp_feature_extraction\\S01_dataset_preprocessing_pipeline.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['label'][df2['label'] == 2] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Seed fixed to 42\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from urllib.parse import urlparse\n",
    "from S01_dataset_preprocessing_pipeline import all_dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "from trainer_class import Trainer\n",
    "tqdm.pandas()\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"âœ… Seed fixed to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357bf0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding structured URLs for Dataset 1 (Malicious URLs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 417732/417732 [01:19<00:00, 5274.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Encoded 417732 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52217/52217 [00:09<00:00, 5285.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: Encoded 52217 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52217/52217 [00:09<00:00, 5243.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Encoded 52217 URLs\n",
      "\n",
      "Encoding structured URLs for Dataset 2 (ndarvind/phiusiil-phishing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188296/188296 [00:23<00:00, 8103.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Encoded 188296 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23537/23537 [00:02<00:00, 7973.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: Encoded 23537 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23537/23537 [00:02<00:00, 8084.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Encoded 23537 URLs\n",
      "\n",
      "Encoding structured URLs for Dataset 3 (kmack/Phishing_urls)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528097/528097 [01:27<00:00, 6051.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Encoded 528097 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66013/66013 [00:10<00:00, 6024.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: Encoded 66013 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66012/66012 [00:10<00:00, 6034.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Encoded 66012 URLs\n",
      "\n",
      "Encoding structured URLs for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405756/405756 [01:13<00:00, 5509.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Encoded 405756 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50720/50720 [00:09<00:00, 5587.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: Encoded 50720 URLs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50719/50719 [00:09<00:00, 5375.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Encoded 50719 URLs\n",
      "\n",
      "All datasets encoded with proper start/end markers and padding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Character Encoding Setup\n",
    "# ============================================================\n",
    "\n",
    "# Allowed printable ASCII chars\n",
    "ascii_chars = [chr(i) for i in range(32, 127)]\n",
    "\n",
    "# Special control tokens\n",
    "special_tokens = [\n",
    "    '<PAD>', '<UNK>',\n",
    "]\n",
    "\n",
    "# Build vocab and mapping\n",
    "vocab = special_tokens + ascii_chars\n",
    "char2idx = {ch: i for i, ch in enumerate(vocab)}\n",
    "\n",
    "\n",
    "\n",
    "def encode(text, max_len=60):\n",
    "    indices = torch.full((max_len,), char2idx[\"<PAD>\"], dtype=torch.long)\n",
    "    text = text.lower()[:max_len]\n",
    "    for i, c in enumerate(text):\n",
    "        indices[i] = char2idx.get(c, char2idx[\"<UNK>\"])\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoded_data = {}\n",
    "frac = 1\n",
    "gen = all_dataset()\n",
    "\n",
    "x=0\n",
    "\n",
    "max_len=128\n",
    "#next(gen)\n",
    "#next(gen)\n",
    "#next(gen)\n",
    "for name, splits in  gen:\n",
    "    encoded_data[name] = {}\n",
    "    print(f\"\\nEncoding structured URLs for {name}...\")\n",
    "\n",
    "    for split_name, df in zip(['train', 'valid', 'test'], splits):\n",
    "        df = df.sample(frac=frac, random_state=42)\n",
    "        df[\"encode\"] = df[\"url\"].progress_apply(lambda url: encode(url, max_len=max_len))\n",
    "        encoded_data[name][split_name] = df\n",
    "        print(f\"{split_name}: Encoded {len(df)} URLs\")\n",
    "\n",
    "\n",
    "    #if x == 1:\n",
    "    #    next(gen)\n",
    "    x+=1\n",
    "\n",
    "\n",
    "print(\"\\nAll datasets encoded with proper start/end markers and padding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbc302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Creating DataLoaders for Dataset 1 (Malicious URLs)...\n",
      "DataLoaders ready for Dataset 1 (Malicious URLs) (Train/Val/Test)\n",
      "\n",
      "ðŸ“¦ Creating DataLoaders for Dataset 2 (ndarvind/phiusiil-phishing)...\n",
      "DataLoaders ready for Dataset 2 (ndarvind/phiusiil-phishing) (Train/Val/Test)\n",
      "\n",
      "ðŸ“¦ Creating DataLoaders for Dataset 3 (kmack/Phishing_urls)...\n",
      "DataLoaders ready for Dataset 3 (kmack/Phishing_urls) (Train/Val/Test)\n",
      "\n",
      "ðŸ“¦ Creating DataLoaders for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)...\n",
      "DataLoaders ready for Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls) (Train/Val/Test)\n",
      "\n",
      "All DataLoaders are ready in `dataloader_dict`!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Convert to TensorDataset and DataLoader\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 1024\n",
    "\n",
    "dataloader_dict = {}\n",
    "\n",
    "def make_tensor_dataset(df):\n",
    "    url_tensor = torch.stack(list(df[\"encode\"]))\n",
    "    labels_tensor = torch.tensor(df[\"label\"].astype(np.float32).values, dtype=torch.long)\n",
    "    return TensorDataset(url_tensor, labels_tensor)\n",
    "\n",
    "for name, splits in encoded_data.items():\n",
    "    dataloader_dict[name] = {}\n",
    "    print(f\"\\nðŸ“¦ Creating DataLoaders for {name}...\")\n",
    "    \n",
    "    train_set = make_tensor_dataset(splits[\"train\"])\n",
    "    val_set = make_tensor_dataset(splits[\"valid\"])\n",
    "    test_set = make_tensor_dataset(splits[\"test\"])\n",
    "    \n",
    "    dataloader_dict[name][\"train_loader\"] = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    dataloader_dict[name][\"val_loader\"] = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    dataloader_dict[name][\"test_loader\"] = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    print(f\"DataLoaders ready for {name} (Train/Val/Test)\")\n",
    "\n",
    "print(\"\\nAll DataLoaders are ready in `dataloader_dict`!\")\n",
    "\n",
    "# Example Access:\n",
    "# dataloader_dict[\"dataset1\"][\"train_loader\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8f1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# =====================================================\n",
    "# ðŸ”¹  Embeding_layer\n",
    "# =====================================================\n",
    "max_len=128\n",
    "vocab_len=97\n",
    "class Embeding_layer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size=256,\n",
    "                 d_model=128,\n",
    "                 max_len=100,\n",
    "                 n_out=128,):\n",
    "        super().__init__()\n",
    "\n",
    "        # Byte embedding layer (0â€“255)\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # Positional embeddings\n",
    "        #self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "        # Final normalization\n",
    "        \n",
    "        self.projection = nn.Linear(in_features=d_model, out_features=n_out)\n",
    "        self.norm = nn.LayerNorm(n_out)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) â€” byte indices [0â€“255]\n",
    "        \"\"\"\n",
    "        #positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        x = self.embedding(x) #+ self.pos_embedding(positions)\n",
    "\n",
    "        x = self.projection(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x  # (B, L, d_model)\n",
    "# ðŸ”¹ Residual Depthwise-Separable Multi-Kernel Block\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_sizes=[3],stride=1, dilations=[1], reduction=16, num_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        #mid_ch = max(in_ch // 16, 8)  # reduce dimension before heavy convs\n",
    "        self.branches = nn.ModuleList()\n",
    "\n",
    "        for k in kernel_sizes:\n",
    "            if k <= 5:\n",
    "                for d in dilations:\n",
    "                    branch = nn.Sequential(\n",
    "                        # (B) Reduce channels first\n",
    "                        #nn.Conv1d(in_ch, 1, kernel_size=1, bias=False),\n",
    "                        \n",
    "                        #nn.GroupNorm(num_groups=8, num_channels=mid_ch),\n",
    "                        #nn.GELU(),\n",
    "                        #nn.Dropout1d(0.25),\n",
    "\n",
    "                        # (A) Depthwise conv\n",
    "                        nn.Conv1d(in_ch, out_ch, kernel_size=k, padding=(k*d-1) // 2, bias=False, stride=stride, dilation=d),\n",
    "\n",
    "\n",
    "                        # Pointwise to expand to out_ch\n",
    "                        #nn.Conv1d(mid_ch, out_ch, kernel_size=1, bias=False),\n",
    "                        #nn.GroupNorm(num_groups=8, num_channels=out_ch),\n",
    "                        #nn.GELU()\n",
    "                    )\n",
    "                    self.branches.append(branch)\n",
    "        \n",
    "        for k in kernel_sizes:\n",
    "            if k > 5:\n",
    "                branch = nn.Sequential(\n",
    "                        nn.Conv1d(in_ch, out_ch, kernel_size=k, padding=(k) // 2, bias=False, stride=stride, dilation=1),\n",
    "                    )\n",
    "                self.branches.append(branch)\n",
    "        \n",
    "        # Combine all kernel branches\n",
    "        self.merge_conv = nn.Conv1d(out_ch * (len(self.branches)), out_ch, kernel_size=1, bias=False)\n",
    "        #self.merge_bn = nn.BatchNorm1d(out_ch)\n",
    "        #self.se = SEBlock(out_ch, reduction)\n",
    "        self.shortcut = nn.Conv1d(in_ch, out_ch, kernel_size=1, stride=stride) if (in_ch != out_ch or stride!=1) else nn.Identity()\n",
    "        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_ch)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout1d(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Parallel multi-kernel branches\n",
    "        out = [branch(x) for branch in self.branches]\n",
    "        out = torch.cat(out, dim=1)\n",
    "\n",
    "        out = self.merge_conv(out)\n",
    "        \n",
    "        #out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.group_norm(out)\n",
    "        out = self.gelu(out)\n",
    "        out = self.dropout(out)\n",
    "        return F.relu(out)\n",
    "\n",
    "    \n",
    "\n",
    "class DualAttentionPooling(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Temporal attention (softmax over T)\n",
    "        self.temporal_attn = nn.Linear(channels, 1)\n",
    "\n",
    "        # Channel attention (SE-style)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "\n",
    "        # ---- Temporal attention ----\n",
    "        t_scores = self.temporal_attn(x)            # (B, T, 1)\n",
    "        t_weights = torch.softmax(t_scores, dim=1)\n",
    "        x = x * t_weights                           # (B, T, C)\n",
    "\n",
    "        # ---- Channel attention ----\n",
    "        c_context = x.mean(dim=1)                   # (B, C)\n",
    "        c_weights = torch.sigmoid(\n",
    "            self.fc2(F.gelu(self.fc1(c_context)))\n",
    "        )                                           # (B, C)\n",
    "\n",
    "        x = x * c_weights.unsqueeze(1)              # (B, T, C)\n",
    "\n",
    "        # ---- Pool ----\n",
    "        return x.sum(dim=1)                         # (B, C)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, d_model]\n",
    "        return x + self.pe[:, :max_len]\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=64, n_heads=4, ff_dim=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        return self.encoder(x, src_key_padding_mask=mask)\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        weights = torch.softmax(self.attn(x), dim=1)\n",
    "        return (weights * x).sum(dim=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import json\n",
    "class URLBinaryCNN_bestmodel(nn.Module):\n",
    "    def __init__(self, maxlen=max_len, vocab_size = vocab_len,d_model=128, embed_dim=64):\n",
    "        super().__init__()\n",
    "        # Shared Layer (Global)\n",
    "        self.shared_layer = nn.ModuleDict({\n",
    "            \"embeding\":  Embeding_layer(vocab_size=vocab_size, max_len=maxlen, d_model=d_model, n_out=embed_dim),\n",
    "            \"conv\": ResidualConvBlock(embed_dim, 64, kernel_sizes=[3,5,7], num_groups=8),\n",
    "            #\"conv2\": ResidualConvBlock(64, 32, kernel_sizes=[3,5,7], num_groups=8),\n",
    "            #\"conv3\": ResidualConvBlockDW(64, 32, kernel_sizes=[3,5,7]),\n",
    "            #\"conv4\": ResidualConvBlockDW(128, 64, kernel_sizes=[3,5,7]),\n",
    "            #\"conv5\": ResidualConvBlockDW(64, 32, kernel_sizes=[3,5,7]),\n",
    "\n",
    "            #\"proj\": nn.Linear(64, 128),\n",
    "            #\"pos_enc\": PositionalEncoding(d_model=64, max_len=maxlen),\n",
    "            #\"transformer\": TransformerBlock(d_model=64, n_heads=4, ff_dim=256, num_layers=1),\n",
    "            \"bilstm\": nn.LSTM(input_size=64, hidden_size=64,num_layers=1, batch_first=True, bidirectional=True),\n",
    "            \"layer_norm\": nn.LayerNorm(64*2),\n",
    "            \"gelu1\": nn.GELU(),\n",
    "            #\"postconv\": nn.Conv1d(64, 32, kernel_size=3),\n",
    "            #\"maxpool\": nn.MaxPool1d(2),\n",
    "            #\"avg_pool1\": nn.AvgPool1d(kernel_size=2),\n",
    "            \"attentionpooling\": DualAttentionPooling(128),\n",
    "            \"fc1\": nn.Linear(128 , 64),\n",
    "            \"layer_normalization1\": nn.LayerNorm(64),\n",
    "            \"gelu2\": nn.GELU(),\n",
    "            \"dropout1\": nn.Dropout(0.25),\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        })\n",
    "\n",
    "        # Personalization Layer (Local)\n",
    "        self.personal_layer = nn.ModuleDict({\n",
    "            \n",
    "            \"fc2\": nn.Linear(64, 48),\n",
    "            \"gelu3\": nn.GELU(),\n",
    "            #\"dropout2\": nn.Dropout(0.25),\n",
    "            \"head\": nn.Linear(48, 1)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shared layers\n",
    "        x = self.shared_layer[\"embeding\"](x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.shared_layer[\"conv\"](x)\n",
    "        #x = self.shared_layer[\"conv2\"](x)\n",
    "        #x = self.shared_layer[\"conv3\"](x)\n",
    "        #x = self.shared_layer[\"max_pool\"](x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        #x = self.shared_layer[\"proj\"](x)          # [B, T, 64]\n",
    "        #x = self.shared_layer[\"pos_enc\"](x)\n",
    "        #x = self.shared_layer[\"transformer\"](x)\n",
    "        x, _ = self.shared_layer[\"bilstm\"](x)\n",
    "        x = self.shared_layer[\"layer_norm\"](x)\n",
    "        x = self.shared_layer[\"gelu1\"](x)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        #x = self.shared_layer[\"postconv\"](x)\n",
    "        #x = self.shared_layer[\"maxpool\"](x)\n",
    "        #x = self.shared_layer[\"avg_pool1\"](x)\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        #x = x[:, -1, :]\n",
    "        #x = x.flatten(1)\n",
    "        x = self.shared_layer[\"attentionpooling\"](x)\n",
    "        x = self.shared_layer[\"dropout1\"](self.shared_layer[\"gelu2\"](self.shared_layer[\"layer_normalization1\"](self.shared_layer[\"fc1\"](x))))\n",
    "        # Personalization head\n",
    "        x = self.personal_layer[\"gelu3\"](self.personal_layer[\"fc2\"](x)) #self.personal_layer[\"dropout2\"](\n",
    "        x = self.personal_layer[\"head\"](x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffba8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fee60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_dim=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda30630",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"best model till now testing\"\n",
    "changes={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14896532",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸš€ Training model on DATASET 1 (MALICIOUS URLS) dataset\n",
      "======================================================================\n",
      "__________ðŸ§© Using 100% of training data___________\n",
      "Run folder created at: training_runs\\2026-01-18_16-35-49_best model till now testing_Dataset 1 (Malicious URLs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\fx\\_symbolic_trace.py:923: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Training global+personal | Batch 400/409 | Loss: 0.1172, Acc: 0.9590 | Val Loss: 0.1095, Val Acc: 0.9637\n",
      " Best Loss Model Saved! Val Loss = 0.1095 | Weights captured  epoch 1\n",
      "Epoch 2/15: Training global+personal | Batch 400/409 | Loss: 0.0949, Acc: 0.9727 | Val Loss: 0.0832, Val Acc: 0.9724\n",
      " Best Loss Model Saved! Val Loss = 0.0832 | Weights captured  epoch 2\n",
      "Epoch 3/15: Training global+personal | Batch 400/409 | Loss: 0.0951, Acc: 0.9658 | Val Loss: 0.0724, Val Acc: 0.9761\n",
      " Best Loss Model Saved! Val Loss = 0.0724 | Weights captured  epoch 3\n",
      "Epoch 4/15: Training global+personal | Batch 400/409 | Loss: 0.0867, Acc: 0.9707 | Val Loss: 0.0695, Val Acc: 0.9771\n",
      " Best Loss Model Saved! Val Loss = 0.0695 | Weights captured  epoch 4\n",
      "Epoch 5/15: Training global+personal | Batch 400/409 | Loss: 0.0951, Acc: 0.9707 | Val Loss: 0.0611, Val Acc: 0.9801\n",
      " Best Loss Model Saved! Val Loss = 0.0611 | Weights captured  epoch 5\n",
      "Epoch 6/15: Training global+personal | Batch 400/409 | Loss: 0.0591, Acc: 0.9785 | Val Loss: 0.0609, Val Acc: 0.9801\n",
      " Best Loss Model Saved! Val Loss = 0.0609 | Weights captured  epoch 6\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 7/15: Training global+personal | Batch 400/409 | Loss: 0.0680, Acc: 0.9756 | Val Loss: 0.0564, Val Acc: 0.9813\n",
      " Best Loss Model Saved! Val Loss = 0.0564 | Weights captured  epoch 7\n",
      "Epoch 8/15: Training global+personal | Batch 400/409 | Loss: 0.0630, Acc: 0.9834 | Val Loss: 0.0539, Val Acc: 0.9822\n",
      " Best Loss Model Saved! Val Loss = 0.0539 | Weights captured  epoch 8\n",
      "Epoch 9/15: Training global+personal | Batch 400/409 | Loss: 0.0705, Acc: 0.9746 | Val Loss: 0.0526, Val Acc: 0.9828\n",
      " Best Loss Model Saved! Val Loss = 0.0526 | Weights captured  epoch 9\n",
      "Epoch 10/15: Training global+personal | Batch 400/409 | Loss: 0.0508, Acc: 0.9834 | Val Loss: 0.0524, Val Acc: 0.9831\n",
      " Best Loss Model Saved! Val Loss = 0.0524 | Weights captured  epoch 10\n",
      "Epoch 11/15: Training global+personal | Batch 400/409 | Loss: 0.0564, Acc: 0.9844 | Val Loss: 0.0514, Val Acc: 0.9831\n",
      " Best Loss Model Saved! Val Loss = 0.0514 | Weights captured  epoch 11\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 12/15: Training global+personal | Batch 400/409 | Loss: 0.0295, Acc: 0.9902 | Val Loss: 0.0505, Val Acc: 0.9833\n",
      " Best Loss Model Saved! Val Loss = 0.0505 | Weights captured  epoch 12\n",
      "Epoch 13/15: Training global+personal | Batch 400/409 | Loss: 0.0542, Acc: 0.9775 | Val Loss: 0.0496, Val Acc: 0.9829\n",
      " Best Loss Model Saved! Val Loss = 0.0496 | Weights captured  epoch 13\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 14/15: Training global+personal | Batch 400/409 | Loss: 0.0624, Acc: 0.9756 | Val Loss: 0.0507, Val Acc: 0.9828\n",
      "No Val Acc improvement (2/5)\n",
      "Epoch 15/15: Training global+personal | Batch 400/409 | Loss: 0.0349, Acc: 0.9854 | Val Loss: 0.0477, Val Acc: 0.9844\n",
      " Best Loss Model Saved! Val Loss = 0.0477 | Weights captured  epoch 15\n",
      "Best threshold (f1): 0.357\n",
      "Best f1: 0.956657\n",
      "âœ… Test metrics saved to: training_runs\\2026-01-18_16-35-49_best model till now testing_Dataset 1 (Malicious URLs)\\test_metrics.json\n",
      "\n",
      "ðŸ“Š Generating graphs...\n",
      "\n",
      "   âœ” Saved batch_loss_vs_batch.png\n",
      "   âœ” Saved batch_acc_vs_batch.png\n",
      "   âœ” Saved batch_loss_vs_time.png\n",
      "   âœ” Saved batch_acc_vs_time.png\n",
      "   âœ” Saved epoch_train_loss_vs_epoch.png\n",
      "âš  Skipped epoch_train_acc_vs_epoch.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_epoch.png\n",
      "   âœ” Saved epoch_val_acc_vs_epoch.png\n",
      "   âœ” Saved epoch_train_loss_vs_time.png\n",
      "âš  Skipped epoch_train_acc_vs_time.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_time.png\n",
      "   âœ” Saved epoch_val_acc_vs_time.png\n",
      "\n",
      "âœ… All available graphs saved in: training_runs\\2026-01-18_16-35-49_best model till now testing_Dataset 1 (Malicious URLs)\\graphs\n",
      "\n",
      "ðŸ“¦ Generating merged layer box plots (depth=2)...\n",
      "\n",
      "   âœ” Saved shared_layer_embeding_merged_boxplot.png\n",
      "   âœ” Saved shared_layer_conv_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_bilstm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_norm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_attentionpooling_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_normalization1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc2_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_head_merged_boxplot.png\n",
      "\n",
      "âœ… Merged layer weight box plots saved in: training_runs\\2026-01-18_16-35-49_best model till now testing_Dataset 1 (Malicious URLs)\\layer_updates\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Training model on DATASET 2 (NDARVIND/PHIUSIIL-PHISHING) dataset\n",
      "======================================================================\n",
      "__________ðŸ§© Using 100% of training data___________\n",
      "Run folder created at: training_runs\\2026-01-18_16-50-23_best model till now testing_Dataset 2 (ndarvind/phiusiil-phishing)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\fx\\_symbolic_trace.py:923: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Training global+personal | Batch 180/185 | Loss: 0.0217, Acc: 0.9961 | Val Loss: 0.0138, Val Acc: 0.9977\n",
      " Best Loss Model Saved! Val Loss = 0.0138 | Weights captured  epoch 1\n",
      "Epoch 2/15: Training global+personal | Batch 180/185 | Loss: 0.0042, Acc: 0.9990 | Val Loss: 0.0117, Val Acc: 0.9980\n",
      " Best Loss Model Saved! Val Loss = 0.0117 | Weights captured  epoch 2\n",
      "Epoch 3/15: Training global+personal | Batch 180/185 | Loss: 0.0084, Acc: 0.9990 | Val Loss: 0.0121, Val Acc: 0.9982\n",
      "Epoch 4/15: Training global+personal | Batch 180/185 | Loss: 0.0299, Acc: 0.9951 | Val Loss: 0.0113, Val Acc: 0.9981\n",
      " Best Loss Model Saved! Val Loss = 0.0113 | Weights captured  epoch 4\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 5/15: Training global+personal | Batch 180/185 | Loss: 0.0024, Acc: 1.0000 | Val Loss: 0.0123, Val Acc: 0.9977\n",
      "No Val Acc improvement (2/5)\n",
      "Epoch 6/15: Training global+personal | Batch 180/185 | Loss: 0.0062, Acc: 0.9990 | Val Loss: 0.0112, Val Acc: 0.9982\n",
      " Best Loss Model Saved! Val Loss = 0.0112 | Weights captured  epoch 6\n",
      "No Val Acc improvement (3/5)\n",
      "Epoch 7/15: Training global+personal | Batch 180/185 | Loss: 0.0085, Acc: 0.9990 | Val Loss: 0.0110, Val Acc: 0.9982\n",
      " Best Loss Model Saved! Val Loss = 0.0110 | Weights captured  epoch 7\n",
      "No Val Acc improvement (4/5)\n",
      "Epoch 8/15: Training global+personal | Batch 180/185 | Loss: 0.0114, Acc: 0.9980 | Val Loss: 0.0109, Val Acc: 0.9983\n",
      " Best Loss Model Saved! Val Loss = 0.0109 | Weights captured  epoch 8\n",
      "No Val Acc improvement (5/5)\n",
      "Early stopping due to validation accuracy plateau. Best Val Acc: 0.9982\n",
      "Best threshold (f1): 0.100\n",
      "Best f1: 0.998556\n",
      "âœ… Test metrics saved to: training_runs\\2026-01-18_16-50-23_best model till now testing_Dataset 2 (ndarvind/phiusiil-phishing)\\test_metrics.json\n",
      "\n",
      "ðŸ“Š Generating graphs...\n",
      "\n",
      "   âœ” Saved batch_loss_vs_batch.png\n",
      "   âœ” Saved batch_acc_vs_batch.png\n",
      "   âœ” Saved batch_loss_vs_time.png\n",
      "   âœ” Saved batch_acc_vs_time.png\n",
      "   âœ” Saved epoch_train_loss_vs_epoch.png\n",
      "âš  Skipped epoch_train_acc_vs_epoch.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_epoch.png\n",
      "   âœ” Saved epoch_val_acc_vs_epoch.png\n",
      "   âœ” Saved epoch_train_loss_vs_time.png\n",
      "âš  Skipped epoch_train_acc_vs_time.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_time.png\n",
      "   âœ” Saved epoch_val_acc_vs_time.png\n",
      "\n",
      "âœ… All available graphs saved in: training_runs\\2026-01-18_16-50-23_best model till now testing_Dataset 2 (ndarvind/phiusiil-phishing)\\graphs\n",
      "\n",
      "ðŸ“¦ Generating merged layer box plots (depth=2)...\n",
      "\n",
      "   âœ” Saved shared_layer_embeding_merged_boxplot.png\n",
      "   âœ” Saved shared_layer_conv_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_bilstm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_norm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_attentionpooling_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_normalization1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc2_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_head_merged_boxplot.png\n",
      "\n",
      "âœ… Merged layer weight box plots saved in: training_runs\\2026-01-18_16-50-23_best model till now testing_Dataset 2 (ndarvind/phiusiil-phishing)\\layer_updates\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Training model on DATASET 3 (KMACK/PHISHING_URLS) dataset\n",
      "======================================================================\n",
      "__________ðŸ§© Using 100% of training data___________\n",
      "Run folder created at: training_runs\\2026-01-18_16-53-58_best model till now testing_Dataset 3 (kmack/Phishing_urls)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\fx\\_symbolic_trace.py:923: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Training global+personal | Batch 500/517 | Loss: 0.3054, Acc: 0.8594 | Val Loss: 0.2725, Val Acc: 0.8886\n",
      " Best Loss Model Saved! Val Loss = 0.2725 | Weights captured  epoch 1\n",
      "Epoch 2/15: Training global+personal | Batch 500/517 | Loss: 0.2728, Acc: 0.8945 | Val Loss: 0.2544, Val Acc: 0.8971\n",
      " Best Loss Model Saved! Val Loss = 0.2544 | Weights captured  epoch 2\n",
      "Epoch 3/15: Training global+personal | Batch 500/517 | Loss: 0.2650, Acc: 0.8789 | Val Loss: 0.2391, Val Acc: 0.9028\n",
      " Best Loss Model Saved! Val Loss = 0.2391 | Weights captured  epoch 3\n",
      "Epoch 4/15: Training global+personal | Batch 500/517 | Loss: 0.2598, Acc: 0.8916 | Val Loss: 0.2332, Val Acc: 0.9050\n",
      " Best Loss Model Saved! Val Loss = 0.2332 | Weights captured  epoch 4\n",
      "Epoch 5/15: Training global+personal | Batch 500/517 | Loss: 0.2380, Acc: 0.8965 | Val Loss: 0.2278, Val Acc: 0.9070\n",
      " Best Loss Model Saved! Val Loss = 0.2278 | Weights captured  epoch 5\n",
      "Epoch 6/15: Training global+personal | Batch 500/517 | Loss: 0.2360, Acc: 0.9023 | Val Loss: 0.2212, Val Acc: 0.9098\n",
      " Best Loss Model Saved! Val Loss = 0.2212 | Weights captured  epoch 6\n",
      "Epoch 7/15: Training global+personal | Batch 500/517 | Loss: 0.2281, Acc: 0.9043 | Val Loss: 0.2215, Val Acc: 0.9102\n",
      "Epoch 8/15: Training global+personal | Batch 500/517 | Loss: 0.2417, Acc: 0.9014 | Val Loss: 0.2174, Val Acc: 0.9116\n",
      " Best Loss Model Saved! Val Loss = 0.2174 | Weights captured  epoch 8\n",
      "Epoch 9/15: Training global+personal | Batch 500/517 | Loss: 0.2260, Acc: 0.9111 | Val Loss: 0.2157, Val Acc: 0.9116\n",
      " Best Loss Model Saved! Val Loss = 0.2157 | Weights captured  epoch 9\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 10/15: Training global+personal | Batch 500/517 | Loss: 0.1879, Acc: 0.9268 | Val Loss: 0.2120, Val Acc: 0.9142\n",
      " Best Loss Model Saved! Val Loss = 0.2120 | Weights captured  epoch 10\n",
      "Epoch 11/15: Training global+personal | Batch 500/517 | Loss: 0.2398, Acc: 0.8975 | Val Loss: 0.2095, Val Acc: 0.9150\n",
      " Best Loss Model Saved! Val Loss = 0.2095 | Weights captured  epoch 11\n",
      "Epoch 12/15: Training global+personal | Batch 500/517 | Loss: 0.2424, Acc: 0.8955 | Val Loss: 0.2155, Val Acc: 0.9117\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 13/15: Training global+personal | Batch 500/517 | Loss: 0.2138, Acc: 0.9121 | Val Loss: 0.2056, Val Acc: 0.9159\n",
      " Best Loss Model Saved! Val Loss = 0.2056 | Weights captured  epoch 13\n",
      "early stoping due to excedding time limit\n",
      "Best threshold (f1): 0.458\n",
      "Best f1: 0.918419\n",
      "âœ… Test metrics saved to: training_runs\\2026-01-18_16-53-58_best model till now testing_Dataset 3 (kmack/Phishing_urls)\\test_metrics.json\n",
      "\n",
      "ðŸ“Š Generating graphs...\n",
      "\n",
      "   âœ” Saved batch_loss_vs_batch.png\n",
      "   âœ” Saved batch_acc_vs_batch.png\n",
      "   âœ” Saved batch_loss_vs_time.png\n",
      "   âœ” Saved batch_acc_vs_time.png\n",
      "   âœ” Saved epoch_train_loss_vs_epoch.png\n",
      "âš  Skipped epoch_train_acc_vs_epoch.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_epoch.png\n",
      "   âœ” Saved epoch_val_acc_vs_epoch.png\n",
      "   âœ” Saved epoch_train_loss_vs_time.png\n",
      "âš  Skipped epoch_train_acc_vs_time.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_time.png\n",
      "   âœ” Saved epoch_val_acc_vs_time.png\n",
      "\n",
      "âœ… All available graphs saved in: training_runs\\2026-01-18_16-53-58_best model till now testing_Dataset 3 (kmack/Phishing_urls)\\graphs\n",
      "\n",
      "ðŸ“¦ Generating merged layer box plots (depth=2)...\n",
      "\n",
      "   âœ” Saved shared_layer_embeding_merged_boxplot.png\n",
      "   âœ” Saved shared_layer_conv_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_bilstm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_norm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_attentionpooling_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_normalization1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc2_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_head_merged_boxplot.png\n",
      "\n",
      "âœ… Merged layer weight box plots saved in: training_runs\\2026-01-18_16-53-58_best model till now testing_Dataset 3 (kmack/Phishing_urls)\\layer_updates\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Training model on DATASET 4 (KAGGELS/TARUNTIWARIHP/PHISHING-SITE-URLS) dataset\n",
      "======================================================================\n",
      "__________ðŸ§© Using 100% of training data___________\n",
      "Run folder created at: training_runs\\2026-01-18_17-10-08_best model till now testing_Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\fx\\_symbolic_trace.py:923: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Training global+personal | Batch 380/398 | Loss: 0.1745, Acc: 0.9355 | Val Loss: 0.1404, Val Acc: 0.9477\n",
      " Best Loss Model Saved! Val Loss = 0.1404 | Weights captured  epoch 1\n",
      "Epoch 2/15: Training global+personal | Batch 380/398 | Loss: 0.0970, Acc: 0.9648 | Val Loss: 0.0955, Val Acc: 0.9665\n",
      " Best Loss Model Saved! Val Loss = 0.0955 | Weights captured  epoch 2\n",
      "Epoch 3/15: Training global+personal | Batch 380/398 | Loss: 0.0843, Acc: 0.9678 | Val Loss: 0.0892, Val Acc: 0.9692\n",
      " Best Loss Model Saved! Val Loss = 0.0892 | Weights captured  epoch 3\n",
      "Epoch 4/15: Training global+personal | Batch 380/398 | Loss: 0.0876, Acc: 0.9717 | Val Loss: 0.0851, Val Acc: 0.9713\n",
      " Best Loss Model Saved! Val Loss = 0.0851 | Weights captured  epoch 4\n",
      "Epoch 5/15: Training global+personal | Batch 380/398 | Loss: 0.0791, Acc: 0.9678 | Val Loss: 0.0767, Val Acc: 0.9734\n",
      " Best Loss Model Saved! Val Loss = 0.0767 | Weights captured  epoch 5\n",
      "Epoch 6/15: Training global+personal | Batch 380/398 | Loss: 0.1002, Acc: 0.9658 | Val Loss: 0.0821, Val Acc: 0.9712\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 7/15: Training global+personal | Batch 380/398 | Loss: 0.0885, Acc: 0.9678 | Val Loss: 0.0692, Val Acc: 0.9764\n",
      " Best Loss Model Saved! Val Loss = 0.0692 | Weights captured  epoch 7\n",
      "Epoch 8/15: Training global+personal | Batch 380/398 | Loss: 0.0635, Acc: 0.9746 | Val Loss: 0.0683, Val Acc: 0.9759\n",
      " Best Loss Model Saved! Val Loss = 0.0683 | Weights captured  epoch 8\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 9/15: Training global+personal | Batch 380/398 | Loss: 0.0712, Acc: 0.9707 | Val Loss: 0.0708, Val Acc: 0.9748\n",
      "No Val Acc improvement (2/5)\n",
      "Epoch 10/15: Training global+personal | Batch 380/398 | Loss: 0.0613, Acc: 0.9756 | Val Loss: 0.0648, Val Acc: 0.9783\n",
      " Best Loss Model Saved! Val Loss = 0.0648 | Weights captured  epoch 10\n",
      "Epoch 11/15: Training global+personal | Batch 380/398 | Loss: 0.0647, Acc: 0.9746 | Val Loss: 0.0620, Val Acc: 0.9791\n",
      " Best Loss Model Saved! Val Loss = 0.0620 | Weights captured  epoch 11\n",
      "Epoch 12/15: Training global+personal | Batch 380/398 | Loss: 0.0699, Acc: 0.9805 | Val Loss: 0.0635, Val Acc: 0.9787\n",
      "No Val Acc improvement (1/5)\n",
      "Epoch 13/15: Training global+personal | Batch 380/398 | Loss: 0.0624, Acc: 0.9707 | Val Loss: 0.0648, Val Acc: 0.9781\n",
      "No Val Acc improvement (2/5)\n",
      "Epoch 14/15: Training global+personal | Batch 380/398 | Loss: 0.0409, Acc: 0.9844 | Val Loss: 0.0611, Val Acc: 0.9796\n",
      " Best Loss Model Saved! Val Loss = 0.0611 | Weights captured  epoch 14\n",
      "Epoch 15/15: Training global+personal | Batch 380/398 | Loss: 0.0572, Acc: 0.9775 | Val Loss: 0.0582, Val Acc: 0.9809\n",
      " Best Loss Model Saved! Val Loss = 0.0582 | Weights captured  epoch 15\n",
      "Best threshold (f1): 0.531\n",
      "Best f1: 0.957753\n",
      "âœ… Test metrics saved to: training_runs\\2026-01-18_17-10-08_best model till now testing_Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\\test_metrics.json\n",
      "\n",
      "ðŸ“Š Generating graphs...\n",
      "\n",
      "   âœ” Saved batch_loss_vs_batch.png\n",
      "   âœ” Saved batch_acc_vs_batch.png\n",
      "   âœ” Saved batch_loss_vs_time.png\n",
      "   âœ” Saved batch_acc_vs_time.png\n",
      "   âœ” Saved epoch_train_loss_vs_epoch.png\n",
      "âš  Skipped epoch_train_acc_vs_epoch.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_epoch.png\n",
      "   âœ” Saved epoch_val_acc_vs_epoch.png\n",
      "   âœ” Saved epoch_train_loss_vs_time.png\n",
      "âš  Skipped epoch_train_acc_vs_time.png â€” missing data\n",
      "   âœ” Saved epoch_val_loss_vs_time.png\n",
      "   âœ” Saved epoch_val_acc_vs_time.png\n",
      "\n",
      "âœ… All available graphs saved in: training_runs\\2026-01-18_17-10-08_best model till now testing_Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\\graphs\n",
      "\n",
      "ðŸ“¦ Generating merged layer box plots (depth=2)...\n",
      "\n",
      "   âœ” Saved shared_layer_embeding_merged_boxplot.png\n",
      "   âœ” Saved shared_layer_conv_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_bilstm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_norm_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_attentionpooling_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_layer_normalization1_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_fc2_merged_boxplot.png\n",
      "   âœ” Saved personal_layer_head_merged_boxplot.png\n",
      "\n",
      "âœ… Merged layer weight box plots saved in: training_runs\\2026-01-18_17-10-08_best model till now testing_Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\\layer_updates\n",
      "\n",
      " All datasets trained successfully!\n",
      "\n",
      "======================================================================\n",
      "Final Validation Accuracy Summary\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from plot_graph import plot_run\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ Training Config\n",
    "# ============================================================\n",
    "num_epochs = [15,0,0]\n",
    "lr_g = 0.001\n",
    "lr_p = 0.001\n",
    "\n",
    "# Store all dataset metrics\n",
    "all_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ” Training Loop for Each Dataset\n",
    "# ============================================================ \n",
    "\n",
    "nn_model = {}\n",
    "save=1\n",
    "for dataset_name, loaders in dataloader_dict.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ðŸš€ Training model on {dataset_name.upper()} dataset\")\n",
    "    print(\"=\"*70)\n",
    "    for frac in  [1]:\n",
    "        print(f\"ðŸ§© Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "        train_loader = loaders[\"train_loader\"]\n",
    "        val_loader = loaders[\"val_loader\"]\n",
    "        nn_model[dataset_name] = URLBinaryCNN_bestmodel(vocab_size=len(vocab), embed_dim=64).to(device)\n",
    "        global_params = []\n",
    "        personal_params = []\n",
    "        for name, param in nn_model[dataset_name].shared_layer.named_parameters():\n",
    "            global_params.append(param)\n",
    "        for name, param in nn_model[dataset_name].personal_layer.named_parameters():\n",
    "            personal_params.append(param)\n",
    "        criterion = nn.BCEWithLogitsLoss() #nn.BCELoss() #\n",
    "        personal_optimizer = torch.optim.AdamW(personal_params, lr=lr_p, weight_decay=2e-4)\n",
    "        global_optimizer = torch.optim.AdamW(global_params, lr=lr_g, weight_decay=1e-4)\n",
    "        personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(personal_optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "        global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(global_optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "        run_name = f\"best model till now testing_{dataset_name}\"\n",
    "        trainer = Trainer(nn_model[dataset_name], criterion,run_name=run_name+str(frac if frac!=1 else ''),dataset_name=dataset_name,changes=changes, train_loader=train_loader, val_loader=val_loader, personal_optimizer=personal_optimizer, global_optimizer=global_optimizer, scheduler_g=global_scheduler, scheduler_p=personal_scheduler, save=save)\n",
    "        # Lists to track performance\n",
    "        trainer.train(num_epochs,frac=frac,val_frac=frac, log=2)\n",
    "        th = trainer.tune_threshold(to_tune='f1')\n",
    "        trainer.test(loaders['test_loader'], th)\n",
    "        if save:plot_run(trainer.run_folder)\n",
    "\n",
    "    '''\n",
    "    # Store all results for this dataset\n",
    "    all_results[dataset_name] = {\n",
    "        \"batch_train_losses\": trainer.batch_train_losses,\n",
    "        \"batch_train_accs\": trainer.batch_train_accs,\n",
    "        \"epoch_train_losses\":  ,\n",
    "        \"epoch_train_accs\": trainer.epoch_train_accs,\n",
    "        \"epoch_val_losses\": trainer.epoch_val_losses,\n",
    "        \"epoch_val_accs\": trainer.epoch_val_accs,\n",
    "        \"batch_times\": trainer.batch_time,\n",
    "        \"epoch_times\": trainer.epoch_time\n",
    "    }\n",
    "    '''\n",
    "print(\"\\n All datasets trained successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary of All Results\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Final Validation Accuracy Summary\")\n",
    "print(\"=\"*70)\n",
    "for name, res in all_results.items():\n",
    "    print(f\"{name:<20} | Val Acc: {res[\"epoch_val_losses\"][-1]:.4f} | Val Loss: {res[\"epoch_val_accs\"][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd12fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_datasets                                    | test_datasets                                                                                                                                       \n",
      "                                                  | Dataset 1 (Malicious URLs)                      | Dataset 2 (ndarvind/phiusiil-phishing)          | Dataset 3 (kmack/Phishing_urls)                 | Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\n",
      "==================================================|=================================================|=================================================|=================================================|\n",
      "Dataset 1 (Malicious URLs)                        | 0.0484,0.9848                                   | 4.9607,0.5738                                   | 3.6343,0.5195                                   | 1.9776,0.6961                                   \n",
      "Dataset 2 (ndarvind/phiusiil-phishing)            | 1.6726,0.8526                                   | 0.0135,0.9977                                   | 5.7253,0.4253                                   | 2.5442,0.7764                                   \n",
      "Dataset 3 (kmack/Phishing_urls)                   | 0.2879,0.8649                                   | 3.1943,0.1144                                   | 0.2074,0.9156                                   | 0.2236,0.8821                                   \n",
      "Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)| 1.5435,0.7786                                   | 3.2820,0.5745                                   | 1.4184,0.7469                                   | 0.0559,0.9811                                   \n"
     ]
    }
   ],
   "source": [
    "#cross dataset accuracy\n",
    "print(\"train_datasets\".ljust(50,' ')+\"| test_datasets\".ljust(150,' '))\n",
    "print(' '*50, end='')\n",
    "for test_datset_name in nn_model:\n",
    "    print(f\"| {test_datset_name}\".ljust(50,' '), end='')\n",
    "print()\n",
    "print('='+(('='*49)+'|')*4)\n",
    "for train_dataset_name in nn_model:\n",
    "    print(f'{train_dataset_name}'.ljust(50,' '), end='')\n",
    "    for test_dataset_name in nn_model.keys():\n",
    "        train_loader = dataloader_dict[test_dataset_name]['train_loader']\n",
    "        test_loader = dataloader_dict[test_dataset_name]['test_loader']\n",
    "        trainer = Trainer(nn_model[train_dataset_name], criterion, train_loader=train_loader, val_loader=test_loader,save=0)\n",
    "        avg_val_loss, val_acc = trainer.evaluate()   \n",
    "        print(f\"| {avg_val_loss:.4f},{val_acc:.4f}\".ljust(50,' '), end='')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc1727",
   "metadata": {},
   "source": [
    "## fedrated learning with persnalization\n",
    "# meta learing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f56025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader_dict.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be08d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b684c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________ðŸ§© Using 10% of training data___________\n"
     ]
    }
   ],
   "source": [
    "#train global model on little part(5%) of dataset\n",
    "dataset_name = 'Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)' #use first dataset as default\n",
    "global_model = URLBinaryCNN_bestmodel(vocab_size=len(vocab), maxlen=128).to(device)\n",
    "loaders = dataloader_dict[dataset_name]\n",
    "train_loader = loaders[\"train_loader\"]\n",
    "val_loader = loaders[\"val_loader\"]\n",
    "lr_p=0.001\n",
    "lr_g=0.001\n",
    "frac = 0.1\n",
    "print(f\"ðŸ§© Using {frac*100:.0f}% of training data\".center(50, '_'))\n",
    "\n",
    "global_params = []\n",
    "persnalization_params = []\n",
    "for name, param in global_model.shared_layer.named_parameters():\n",
    "    global_params.append(param)\n",
    "for name, param in global_model.personal_layer.named_parameters():\n",
    "    persnalization_params.append(param)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "g_personal_optimizer = torch.optim.NAdam(persnalization_params, lr=lr_p, weight_decay=lr_p/10)\n",
    "g_global_optimizer = torch.optim.NAdam(global_params, lr=lr_g, weight_decay=lr_g/10)\n",
    "g_personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(g_personal_optimizer, mode='min', factor=0.5, patience=1)\n",
    "g_global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(g_global_optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "trainer = Trainer(global_model, criterion, train_loader=train_loader, val_loader=val_loader, personal_optimizer=g_personal_optimizer, global_optimizer=g_global_optimizer, scheduler_g=g_global_scheduler, scheduler_p=g_personal_scheduler,save=0)\n",
    "        \n",
    "# Lists to track performance\n",
    "trainer.train(epochs_list=[0,0,0],frac=frac,val_frac=frac, log=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ed775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeding.embedding.weight\n",
      "embeding.projection.weight\n",
      "embeding.projection.bias\n",
      "embeding.norm.weight\n",
      "embeding.norm.bias\n",
      "conv.branches.0.0.weight\n",
      "conv.branches.1.0.weight\n",
      "conv.branches.2.0.weight\n",
      "conv.merge_conv.weight\n",
      "conv.group_norm.weight\n",
      "conv.group_norm.bias\n",
      "bilstm.weight_ih_l0\n",
      "bilstm.weight_hh_l0\n",
      "bilstm.bias_ih_l0\n",
      "bilstm.bias_hh_l0\n",
      "bilstm.weight_ih_l0_reverse\n",
      "bilstm.weight_hh_l0_reverse\n",
      "bilstm.bias_ih_l0_reverse\n",
      "bilstm.bias_hh_l0_reverse\n",
      "layer_norm.weight\n",
      "layer_norm.bias\n",
      "attentionpooling.temporal_attn.weight\n",
      "attentionpooling.temporal_attn.bias\n",
      "attentionpooling.fc1.weight\n",
      "attentionpooling.fc1.bias\n",
      "attentionpooling.fc2.weight\n",
      "attentionpooling.fc2.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "layer_normalization1.weight\n",
      "layer_normalization1.bias\n"
     ]
    }
   ],
   "source": [
    "for i,j in global_model.shared_layer.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28386161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedrative_larning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6204e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from trainer_class import Trainer\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def make_tensor_dataset(df):\n",
    "    url_tensor = torch.stack(list(df[\"encode\"]))\n",
    "    labels_tensor = torch.tensor(df[\"label\"].astype(np.float32).values, dtype=torch.long)\n",
    "    return TensorDataset(url_tensor, labels_tensor)\n",
    "def make_clients(global_model, train_dataset,val_dataset, dataset_name, num_clients=5, alpha=0.5, total_data=1, batch_size=256, max_train_samples_per_client=50000, max_val_samples_per_client=8000):\n",
    "    import numpy as np\n",
    "    # using alpha to produce unidentical splits high alpha more identical\n",
    "    client_fractions = np.random.dirichlet([alpha] * num_clients) * total_data\n",
    "    total_train_len = int(len(train_dataset) * total_data)\n",
    "    total_val_len   = int(len(val_dataset) * total_data)\n",
    "    train_start = 0\n",
    "    val_start = 0\n",
    "    client_models = []\n",
    "    for i in range(num_clients):\n",
    "        train_size = int(client_fractions[i] * total_train_len)\n",
    "        val_size   = int(client_fractions[i] * total_val_len)\n",
    "\n",
    "        train_size = min(train_size, max_train_samples_per_client)\n",
    "        val_size   = min(val_size, max_val_samples_per_client)\n",
    "\n",
    "        train_end = min(train_start + train_size, len(train_dataset))\n",
    "        val_end   = min(val_start + val_size, len(val_dataset))\n",
    "\n",
    "        train_slice = train_dataset.iloc[train_start:train_end]\n",
    "        val_slice   = val_dataset.iloc[val_start:val_end]\n",
    "\n",
    "        train_start = train_end\n",
    "        val_start   = val_end\n",
    "\n",
    "        client_model = URLBinaryCNN_bestmodel(vocab_size=97, maxlen=128).to(device)                     # fresh instance\n",
    "        client_model.shared_layer.load_state_dict(global_model.shared_layer.state_dict())\n",
    "        train_set = make_tensor_dataset(train_slice)\n",
    "        val_set   = make_tensor_dataset(val_slice)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "        client_models.append({'model':client_model, 'train_loader':train_loader,'val_loader':val_loader, 'val_acc':0, 'dataset':dataset_name})\n",
    "    return client_models, client_fractions\n",
    "\n",
    "\n",
    "def quick_fine_tune(model, train_loader, personal_optimizer,frac=1, epochs=1):\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # â–¶â–¶ added save=0\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        criterion=criterion,\n",
    "        train_loader=train_loader,\n",
    "        personal_optimizer=personal_optimizer,\n",
    "        save=0\n",
    "    )\n",
    "\n",
    "    trainer.train(epochs_list=[0,0,epochs], frac=frac, log=0, skip_phase=0)\n",
    "\n",
    "\n",
    "def train_client(client_devices, epoch=1):\n",
    "    print(\"training client models: \")\n",
    "    client_acc = []\n",
    "    client_losses = []\n",
    "    for i, client_device in enumerate(client_devices):\n",
    "        print('\\tclient ',i,'dataset', client_device['dataset'][8], end=' ')\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        lr_p = 0.001\n",
    "        lr_g = 0.0005\n",
    "\n",
    "        personal_optimizer = torch.optim.NAdam(client_device['model'].personal_layer.parameters(), lr=lr_p, weight_decay=lr_p/10)\n",
    "        global_optimizer = torch.optim.NAdam(client_device['model'].shared_layer.parameters(), lr=lr_g, weight_decay=lr_g/10)\n",
    "\n",
    "        personal_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            personal_optimizer, mode='min', factor=0.5, patience=1\n",
    "        )\n",
    "        global_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            global_optimizer, mode='min', factor=0.5, patience=1\n",
    "        )\n",
    "\n",
    "        # â–¶â–¶ added save=0\n",
    "        trainer = Trainer(\n",
    "            client_device['model'],\n",
    "            criterion=criterion,\n",
    "            train_loader=client_device['train_loader'],\n",
    "            val_loader=client_device['val_loader'],\n",
    "            personal_optimizer=personal_optimizer,\n",
    "            global_optimizer=global_optimizer,\n",
    "            scheduler_g=global_scheduler,\n",
    "            scheduler_p=personal_scheduler,\n",
    "            save=0\n",
    "        )\n",
    "\n",
    "        trainer.train(epochs_list=[epoch,0,0],log=0)\n",
    "        #print(\"epoch accuracies:-\", trainer.epoch_val_accs)\n",
    "        client_losses.append(trainer.epoch_val_losses)\n",
    "        client_acc.append(trainer.epoch_val_accs)\n",
    "    print()\n",
    "    return client_losses, client_acc\n",
    "\n",
    "\n",
    "def fed_meta_learing(global_model, client_devices,train_loader, global_personal_optimizer, meta_lr=0.1, quick_tune_epoch = 2):\n",
    "    total_samples = sum(len(client_device['train_loader'].dataset) for client_device in client_devices)\n",
    "    trim_ratio = 0.2  # 10% trimming\n",
    "    num_clients = len(client_devices)\n",
    "    k = int(trim_ratio * num_clients)\n",
    "\n",
    "    weights = [\n",
    "        len(client_device['train_loader'].dataset) / total_samples\n",
    "        for client_device in client_devices\n",
    "    ]\n",
    "    global_state = {\n",
    "        **global_model.shared_layer.state_dict()\n",
    "    }\n",
    "\n",
    "    avg_state = copy.deepcopy(global_state)\n",
    "    '''\n",
    "    for key in avg_state.keys():\n",
    "\n",
    "        # 1. Collect all client tensors for this parameter\n",
    "        client_tensors = []\n",
    "        for i, client_device in enumerate(client_devices):\n",
    "            client_state = client_device['model'].shared_layer.state_dict()\n",
    "            client_tensors.append(client_state[key])\n",
    "\n",
    "        # Shape: [num_clients, *param_shape]\n",
    "        stacked = torch.stack(client_tensors, dim=0)\n",
    "\n",
    "        # 2. Sort across client dimension\n",
    "        sorted_tensor, _ = torch.sort(stacked, dim=0)\n",
    "\n",
    "        # 3. Trim extremes\n",
    "        if k > 0:\n",
    "            trimmed_tensor = sorted_tensor[k:-k]\n",
    "        else:\n",
    "            trimmed_tensor = sorted_tensor\n",
    "\n",
    "        # 4. Mean of remaining values\n",
    "        avg_state[key] = torch.mean(trimmed_tensor, dim=0)\n",
    "    '''\n",
    "    for key in avg_state.keys():\n",
    "        avg_state[key] = torch.zeros_like(avg_state[key])\n",
    "        for client_device, w in zip(client_devices, weights):\n",
    "            client_state = {\n",
    "                **client_device['model'].shared_layer.state_dict(),\n",
    "            #**client_model.personal_layer.state_dict()\n",
    "            }\n",
    "            avg_state[key] += client_state[key] * w\n",
    "\n",
    "    new_state = {}\n",
    "    for key in global_state.keys():\n",
    "        new_state[key] = global_state[key] + meta_lr * (avg_state[key] - global_state[key])\n",
    "\n",
    "\n",
    "    global_model.shared_layer.load_state_dict({\n",
    "        k: v for k, v in new_state.items() if k in global_model.shared_layer.state_dict()\n",
    "    })\n",
    "    quick_fine_tune(global_model,train_loader,global_personal_optimizer,  0.1, epochs=quick_tune_epoch)\n",
    "\n",
    "def soft_update(client, global_model, alpha=0.3):\n",
    "    for c_p, g_p in zip(client.shared_layer.parameters(), global_model.shared_layer.parameters()):\n",
    "        c_p.data = c_p.data + alpha * (g_p.data - c_p.data)\n",
    "\n",
    "def update_clients(client_devices, global_model, alpha=0.3, quick_tune_epoch = 3):\n",
    "    #client_acc_avg = sum([client_device['val_acc'] for client_device in client_devices])/len(client_devices)\n",
    "    #client_std = sum([(client_device['val_acc']-client_acc_avg)**2 for client_device in client_devices])/len(client_devices)**(1/2)\n",
    "    for i, client_device in enumerate(client_devices):\n",
    "        client_device['model'].shared_layer.load_state_dict(global_model.shared_layer.state_dict())\n",
    "        soft_update(client=client_device['model'], global_model=global_model, alpha=alpha)\n",
    "\n",
    "        personal_optimizer = torch.optim.AdamW(client_device['model'].personal_layer.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        #client.personal_layer.load_state_dict(global_model.shared_layer.state_dict())\n",
    "        quick_fine_tune(client_device['model'], client_device['train_loader'], personal_optimizer,epochs=quick_tune_epoch)\n",
    "        pass\n",
    "def evaluate_client(client_devices):\n",
    "    avg_val_losses, val_accs = [], []\n",
    "    for i, client_device in enumerate(client_devices):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        trainer = Trainer(client_device['model'], criterion=criterion, train_loader=client_device['train_loader'], val_loader=client_device['val_loader'],save=0)\n",
    "        avg_val_loss, val_acc = trainer.evaluate()\n",
    "        avg_val_losses.append(avg_val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        client_device['val_acc'] = val_acc\n",
    "    return avg_val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1268aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Malicious URLs)\n",
      "Dataset 2 (ndarvind/phiusiil-phishing)\n",
      "Dataset 3 (kmack/Phishing_urls)\n",
      "Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\n",
      "[np.float64(0.6), np.float64(0.6), np.float64(0.6), np.float64(0.6)]\n",
      "clints initial accuracy\n",
      "0.7770406136512756 0.175375 0.6\n",
      "0.6981279802322388 0.57875 0.6\n",
      "0.697447416305542 0.495 0.6\n",
      "0.716227562904358 0.22525 0.6\n"
     ]
    }
   ],
   "source": [
    "client_devices, client_fractions = [], []\n",
    "for Dataset_name in encoded_data:\n",
    "    client_device, client_fraction = make_clients(global_model=global_model, num_clients=1, train_dataset=encoded_data[Dataset_name]['train'], val_dataset=encoded_data[Dataset_name]['valid'], dataset_name=Dataset_name, total_data=0.60,alpha=10, batch_size=256) \n",
    "    client_devices.extend(client_device)\n",
    "    client_fractions.extend(client_fraction)\n",
    "    print(Dataset_name)\n",
    "\n",
    "print(client_fractions)\n",
    "print('clints initial accuracy')\n",
    "avg_val_losses, val_accs = evaluate_client(client_devices)\n",
    "for i, (avg_val_loss, val_acc) in enumerate(zip(avg_val_losses,val_accs)):\n",
    "    print(avg_val_loss, val_acc, client_fractions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9af6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "class FLLogger:\n",
    "    def __init__(self, base_dir=\"runs\", run_name=None):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        self.run_name =  f\"{timestamp}_{run_name if run_name else ''}\"\n",
    "        self.run_dir = os.path.join(base_dir, self.run_name)\n",
    "\n",
    "        os.makedirs(self.run_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.run_dir, \"checkpoints\"), exist_ok=True)\n",
    "\n",
    "        self.global_metrics = {\n",
    "            \"loss\": [],\n",
    "            \"accuracy\": []\n",
    "        }\n",
    "\n",
    "        self.client_metrics = {}\n",
    "\n",
    "    # ------------------------------\n",
    "    def save_config(self, config: dict):\n",
    "        with open(os.path.join(self.run_dir, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "\n",
    "    # ------------------------------\n",
    "    def log_global_muti(self, loss, acc):\n",
    "        self.global_metrics[\"loss\"].extend(loss)\n",
    "        self.global_metrics[\"accuracy\"].extend(acc)\n",
    "    def log_global(self, loss, acc):\n",
    "        self.global_metrics[\"loss\"].append(float(loss))\n",
    "        self.global_metrics[\"accuracy\"].append(float(acc))\n",
    "\n",
    "    # ------------------------------\n",
    "    def log_client(self, client_id, loss, acc):\n",
    "        if client_id not in self.client_metrics:\n",
    "            self.client_metrics[client_id] = {\n",
    "                \"loss\": [],\n",
    "                \"accuracy\": []\n",
    "            }\n",
    "        self.client_metrics[client_id][\"loss\"].append(float(loss))\n",
    "        self.client_metrics[client_id][\"accuracy\"].append(float(acc))\n",
    "\n",
    "    # ------------------------------\n",
    "    def save_checkpoint(self, model, epoch):\n",
    "        path = os.path.join(\n",
    "            self.run_dir, \"checkpoints\", f\"global_epoch_{epoch}.pt\"\n",
    "        )\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    # ------------------------------\n",
    "    def flush(self):\n",
    "        with open(os.path.join(self.run_dir, \"global_metrics.json\"), \"w\") as f:\n",
    "            json.dump(self.global_metrics, f, indent=4)\n",
    "\n",
    "        with open(os.path.join(self.run_dir, \"client_metrics.json\"), \"w\") as f:\n",
    "            json.dump(self.client_metrics, f, indent=4)\n",
    "\n",
    "        summary = {\n",
    "            \"final_global_loss\": self.global_metrics[\"loss\"][-1],\n",
    "            \"final_global_accuracy\": self.global_metrics[\"accuracy\"][-1],\n",
    "            \"num_clients\": len(self.client_metrics)\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(self.run_dir, \"summary.json\"), \"w\") as f:\n",
    "            json.dump(summary, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f929cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch '1' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrpra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tglobal model loss 0.4092 accuracy 0.8534\n",
      "global epoch '2' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.2669 accuracy 0.8988\n",
      "global epoch '3' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.2227 accuracy 0.9142\n",
      "global epoch '4' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1982 accuracy 0.9237\n",
      "global epoch '5' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1691 accuracy 0.9385\n",
      "global epoch '6' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1544 accuracy 0.9442\n",
      "global epoch '7' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1545 accuracy 0.9421\n",
      "global epoch '8' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1409 accuracy 0.9473\n",
      "global epoch '9' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1331 accuracy 0.9507\n",
      "global epoch '10' training client models: \n",
      "\tclient  0 dataset 1 \tclient  1 dataset 2 \tclient  2 dataset 3 \tclient  3 dataset 4 \n",
      "\tglobal model loss 0.1271 accuracy 0.9535\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(global_model, criterion, train_loader=train_loader, val_loader=val_loader,save=0)\n",
    "\n",
    "global_epoch = 10\n",
    "client_epoch = 1\n",
    "\n",
    "logger = FLLogger(run_name=\"fed_trimed_avgv3\")\n",
    "\n",
    "logger.save_config({\n",
    "    \"global_epochs\": global_epoch,\n",
    "    \"client_epochs\": client_epoch,\n",
    "    \"num_clients\": len(client_devices),\n",
    "    \"meta_lr\": 0.2,\n",
    "    \"soft_alpha\": 0.4,\n",
    "    \"client_quick_epochs\": 3,\n",
    "    \"global_quick_epochs\": 2,\n",
    "    \"optimizer\": \"NAdam\",\n",
    "    \"loss\": \"BCELoss\",\n",
    "    \"model\": \"URLBinaryCNN\"\n",
    "})\n",
    "\n",
    "\n",
    "trainer = Trainer(global_model, criterion, train_loader=train_loader, val_loader=val_loader,save=0)\n",
    "for i in range(global_epoch):\n",
    "    print(f\"global epoch '{i+1}' \", end=\"\")\n",
    "    losses, accuracies = train_client(client_devices, epoch=client_epoch)\n",
    "\n",
    "    for cid, (loss_list, acc_list) in enumerate(zip(losses, accuracies)):\n",
    "        for l, a in zip(loss_list, acc_list):\n",
    "            logger.log_client(cid, l, a)\n",
    "    loss, acc = trainer.evaluate(frac=0.1)\n",
    "    logger.log_global(loss, acc)\n",
    "\n",
    "    # ---- Server update\n",
    "    fed_meta_learing(global_model, client_devices,train_loader=train_loader, global_personal_optimizer=g_personal_optimizer, meta_lr=0.8, quick_tune_epoch=1)\n",
    "\n",
    "    # ---- Update clients\n",
    "    update_clients(client_devices, global_model, alpha=0.7, quick_tune_epoch=1)\n",
    "\n",
    "    # ---- Client evaluation\n",
    "    losses, accuracies = evaluate_client(client_devices)\n",
    "    for cid, (l, a) in enumerate(zip(losses, accuracies)):\n",
    "        logger.log_client(cid, l, a)\n",
    "\n",
    "    # ---- Global eval again\n",
    "    loss, acc = trainer.evaluate(frac=0.1)\n",
    "    logger.log_global(loss, acc)\n",
    "\n",
    "    # ---- Save checkpoint\n",
    "    logger.save_checkpoint(global_model, i)\n",
    "\n",
    "    print(f\"\\tglobal model loss {loss:.4f} accuracy {acc:.4f}\")\n",
    "logger.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0903a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "legendgroup": "Dataset 1 ",
         "line": {
          "color": "#2E91E5"
         },
         "marker": {
          "color": "#2E91E5"
         },
         "mode": "lines+markers",
         "name": "client1 Dataset 1 ",
         "opacity": 0.4,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x",
         "y": [
          0.16710150176286698,
          0.17652102303504943,
          0.13830534040927886,
          0.15149352633953095,
          0.12458221840858459,
          0.13834989446401597,
          0.11596688103675842,
          0.12331116408109664,
          0.11451884877681733,
          0.11414739370346069,
          0.10214373922348022,
          0.1082424910068512,
          0.09746121466159821,
          0.10284470963478089,
          0.11807817041873932,
          0.09509795701503754,
          0.09719873201847076,
          0.09159587287902832,
          0.09353634190559387,
          0.08907218313217163
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "Dataset 2 ",
         "line": {
          "color": "#E15F99"
         },
         "marker": {
          "color": "#E15F99"
         },
         "mode": "lines+markers",
         "name": "client2 Dataset 2 ",
         "opacity": 0.4,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x",
         "y": [
          0.011524142222478986,
          0.010533991913311183,
          0.010059432010864839,
          0.009659678935538978,
          0.00923252836894244,
          0.009024248075205833,
          0.008378073035739363,
          0.008955323457717896,
          0.008637351397424936,
          0.00845314704813063,
          0.00879588177241385,
          0.009262534401379526,
          0.00792692767083645,
          0.008839316328521817,
          0.008260025389492512,
          0.008657361043151467,
          0.00794933861680329,
          0.008565594462677836,
          0.008230022266507148,
          0.008229399836622178
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "Dataset 3 ",
         "line": {
          "color": "#1CA71C"
         },
         "marker": {
          "color": "#1CA71C"
         },
         "mode": "lines+markers",
         "name": "client3 Dataset 3 ",
         "opacity": 0.4,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x",
         "y": [
          0.3938292453289032,
          0.4172717134952545,
          0.38125367045402525,
          0.3967775502204895,
          0.3461081976890564,
          0.3493336281776428,
          0.3386906752586365,
          0.34038805508613584,
          0.32403775668144225,
          0.3206469362974167,
          0.30628351378440855,
          0.31077651619911195,
          0.30274401092529296,
          0.31754679131507874,
          0.3234613196849823,
          0.2945091252326965,
          0.2972766191959381,
          0.3354001817703247,
          0.33959024381637576,
          0.2932858016490936
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "Dataset 4 ",
         "line": {
          "color": "#FB0D0D"
         },
         "marker": {
          "color": "#FB0D0D"
         },
         "mode": "lines+markers",
         "name": "client4 Dataset 4 ",
         "opacity": 0.4,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x",
         "y": [
          0.2788588318824768,
          0.2688033421039581,
          0.21415038645267487,
          0.2272384682893753,
          0.20336602884531021,
          0.21636691838502883,
          0.1840619500875473,
          0.18016811102628708,
          0.16235787409543992,
          0.15820329421758653,
          0.1497990683913231,
          0.15012894958257675,
          0.20108113765716554,
          0.13884824591875075,
          0.20624415040016175,
          0.13378923439979554,
          0.12953337997198106,
          0.1369084837436676,
          0.128499342918396,
          0.14367422449588776
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "global",
         "line": {
          "color": "black",
          "width": 3
         },
         "marker": {
          "color": "black",
          "size": 8,
          "symbol": "square"
         },
         "mode": "lines+markers",
         "name": "Global Model",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "xaxis": "x",
         "y": [
          0.7681344946225485,
          0.40917638937632245,
          0.266938919822375,
          0.22271083543697992,
          0.19819718599319458,
          0.16912643611431122,
          0.15439814453323683,
          0.1545073315501213,
          0.1409048611919085,
          0.13313310841719309
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "Dataset 1 ",
         "line": {
          "color": "#2E91E5"
         },
         "marker": {
          "color": "#2E91E5"
         },
         "mode": "lines+markers",
         "name": "client1 Dataset 1 ",
         "opacity": 0.4,
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.939875,
          0.936625,
          0.952125,
          0.947375,
          0.956125,
          0.952375,
          0.9595,
          0.958125,
          0.961375,
          0.96225,
          0.966375,
          0.96375,
          0.96975,
          0.967625,
          0.958625,
          0.96925,
          0.9685,
          0.970625,
          0.97075,
          0.969875
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "Dataset 2 ",
         "line": {
          "color": "#E15F99"
         },
         "marker": {
          "color": "#E15F99"
         },
         "mode": "lines+markers",
         "name": "client2 Dataset 2 ",
         "opacity": 0.4,
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.998,
          0.998125,
          0.998375,
          0.99825,
          0.9985,
          0.998625,
          0.998625,
          0.998375,
          0.9985,
          0.998625,
          0.9985,
          0.998375,
          0.998875,
          0.998625,
          0.99875,
          0.998625,
          0.99875,
          0.9985,
          0.998625,
          0.998625
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "Dataset 3 ",
         "line": {
          "color": "#1CA71C"
         },
         "marker": {
          "color": "#1CA71C"
         },
         "mode": "lines+markers",
         "name": "client3 Dataset 3 ",
         "opacity": 0.4,
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.830125,
          0.810375,
          0.82675,
          0.81925,
          0.8565,
          0.851,
          0.85775,
          0.858,
          0.867,
          0.868875,
          0.875875,
          0.873375,
          0.87875,
          0.86775,
          0.864875,
          0.8805,
          0.87875,
          0.859875,
          0.86425,
          0.879375
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "Dataset 4 ",
         "line": {
          "color": "#FB0D0D"
         },
         "marker": {
          "color": "#FB0D0D"
         },
         "mode": "lines+markers",
         "name": "client4 Dataset 4 ",
         "opacity": 0.4,
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.89475,
          0.89475,
          0.922375,
          0.9145,
          0.9265,
          0.916625,
          0.933625,
          0.931625,
          0.940875,
          0.942,
          0.943625,
          0.945125,
          0.920875,
          0.94825,
          0.917375,
          0.9505,
          0.953125,
          0.949,
          0.9545,
          0.946
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "global",
         "line": {
          "color": "black",
          "width": 3
         },
         "marker": {
          "color": "black",
          "size": 8,
          "symbol": "square"
         },
         "mode": "lines+markers",
         "name": "Global Model",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.22867838541666666,
          0.8533528645833334,
          0.8987630208333334,
          0.9142252604166666,
          0.9236653645833334,
          0.9384765625,
          0.9441731770833334,
          0.9420572916666666,
          0.947265625,
          0.95068359375
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Loss (Clients vs Global)",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Accuracy (Clients vs Global)",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 520,
        "hovermode": "x unified",
        "shapes": [
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 1,
          "x1": 1,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 1,
          "x1": 1,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 2,
          "x1": 2,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 2,
          "x1": 2,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 3,
          "x1": 3,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 3,
          "x1": 3,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 4,
          "x1": 4,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 4,
          "x1": 4,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 5,
          "x1": 5,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 5,
          "x1": 5,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 6,
          "x1": 6,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 6,
          "x1": 6,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 7,
          "x1": 7,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 7,
          "x1": 7,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 8,
          "x1": 8,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 8,
          "x1": 8,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 9,
          "x1": 9,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 9,
          "x1": 9,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 10,
          "x1": 10,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash",
           "width": 1
          },
          "type": "line",
          "x0": 10,
          "x1": 10,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Evaluation Step"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Evaluation Step"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Validation Loss (Clients vs Global)\",\n",
    "        \"Validation Accuracy (Clients vs Global)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assign fixed colors per client\n",
    "palette = px.colors.qualitative.Dark24  # journal-friendly\n",
    "client_colors = {\n",
    "    client_id: palette[client_id % len(palette)]\n",
    "    for client_id in logger.client_metrics.keys()\n",
    "}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Subplot 1: Validation Loss (Clients)\n",
    "for client_id, metrics in logger.client_metrics.items():\n",
    "    losses = metrics[\"loss\"]\n",
    "    steps = [x / (client_epoch + 1)\n",
    "             for x in range(1, client_epoch * global_epoch + global_epoch + 1)]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=steps,\n",
    "            y=losses,\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"client{client_id + 1} {client_devices[client_id]['dataset'][:10]}\",\n",
    "            legendgroup=f\"{client_devices[client_id]['dataset'][:10]}\",\n",
    "            line=dict(color=client_colors[client_id]),\n",
    "            marker=dict(color=client_colors[client_id]),\n",
    "            opacity=0.4\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Global model loss\n",
    "global_losses = logger.global_metrics[\"loss\"][::2]\n",
    "global_steps = list(range(1, len(global_losses) + 1))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=global_steps,\n",
    "        y=global_losses,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Global Model\",\n",
    "        legendgroup=\"global\",\n",
    "        line=dict(color=\"black\", width=3),\n",
    "        marker=dict(symbol=\"square\", size=8, color=\"black\")\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Subplot 2: Validation Accuracy (Clients)\n",
    "for client_id, metrics in logger.client_metrics.items():\n",
    "    accuracies = metrics[\"accuracy\"]\n",
    "    steps = [x / (client_epoch + 1)\n",
    "             for x in range(1, client_epoch * global_epoch + global_epoch + 1)]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=steps,\n",
    "            y=accuracies,\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"client{client_id + 1} {client_devices[client_id]['dataset'][:10]}\",\n",
    "            legendgroup=f\"{client_devices[client_id]['dataset'][:10]}\",\n",
    "            showlegend=False,  # legend only once (left plot)\n",
    "            line=dict(color=client_colors[client_id]),\n",
    "            marker=dict(color=client_colors[client_id]),\n",
    "            opacity=0.4\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Global model accuracy\n",
    "global_accs = logger.global_metrics[\"accuracy\"][::2]\n",
    "global_steps = list(range(1, len(global_accs) + 1))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=global_steps,\n",
    "        y=global_accs,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Global Model\",\n",
    "        legendgroup=\"global\",\n",
    "        showlegend=False,\n",
    "        line=dict(color=\"black\", width=3),\n",
    "        marker=dict(symbol=\"square\", size=8, color=\"black\")\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Axis labels\n",
    "fig.update_xaxes(title_text=\"Evaluation Step\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Evaluation Step\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", row=1, col=2)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Vertical lines (Global Rounds)\n",
    "for g in range(1, global_epoch + 1):\n",
    "    fig.add_vline(\n",
    "        x=g,\n",
    "        line=dict(color=\"orange\", dash=\"dash\", width=1)\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    height=520,\n",
    "    width=1200,\n",
    "    template=\"plotly_white\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1e1b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Malicious URLs)\n",
      "Dataset 2 (ndarvind/phiusiil-phishing)\n",
      "Dataset 3 (kmack/Phishing_urls)\n",
      "Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\n",
      "[np.float64(0.5999999999999999), np.float64(0.6), np.float64(0.6), np.float64(0.5999999999999999)]\n",
      "clints initial accuracy\n",
      "0.7501703991889953 0.168625 0.5999999999999999\n",
      "0.7081740617752075 0.420875 0.6\n",
      "0.6776898002624512 0.70775 0.6\n",
      "0.7369753570556641 0.103625 0.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "# test fast addaption\n",
    "client_devices, client_fractions = [], []\n",
    "for Dataset_name in encoded_data:\n",
    "    client_device, client_fraction = make_clients(global_model=global_model, num_clients=1, train_dataset=encoded_data[Dataset_name]['train'], val_dataset=encoded_data[Dataset_name]['valid'], dataset_name=Dataset_name, total_data=0.60,alpha=10, batch_size=256) \n",
    "    client_devices.extend(client_device)\n",
    "    client_fractions.extend(client_fraction)\n",
    "    print(Dataset_name)\n",
    "\n",
    "print(client_fractions)\n",
    "print('clints initial accuracy')\n",
    "avg_val_losses, val_accs = evaluate_client(client_devices)\n",
    "for i, (avg_val_loss, val_acc) in enumerate(zip(avg_val_losses,val_accs)):\n",
    "    print(avg_val_loss, val_acc, client_fractions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9df643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Malicious URLs)\n",
      "quick fine tuning to test fast addaption of new clients\n",
      "early stoping due to excedding time limit\n",
      "Dataset 2 (ndarvind/phiusiil-phishing)\n",
      "quick fine tuning to test fast addaption of new clients\n",
      "Dataset 3 (kmack/Phishing_urls)\n",
      "quick fine tuning to test fast addaption of new clients\n",
      "Dataset 4 (kaggels/taruntiwarihp/phishing-site-urls)\n",
      "quick fine tuning to test fast addaption of new clients\n",
      "([0.13687008821964264, 0.014332186251878739, 0.30992029345035554, 0.13212498843669893], [0.955125, 0.996375, 0.874875, 0.9515])\n"
     ]
    }
   ],
   "source": [
    "for client_device in client_devices:\n",
    "    print(client_device['dataset'])\n",
    "    print(\"quick fine tuning to test fast addaption of new clients\")\n",
    "    personal_optimizer = torch.optim.AdamW(client_device['model'].personal_layer.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    quick_fine_tune(client_device['model'], client_device['train_loader'],personal_optimizer,epochs=2)\n",
    "print(evaluate_client(client_devices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
